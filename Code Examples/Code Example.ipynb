{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the classes from the \"utils\" folder\n",
    "\n",
    "from utils.text_preprocessing import TextPreprocessing\n",
    "from utils.neural_embedding_models import NeuralEmbeddingModels\n",
    "from utils.embedding_validation import EmbeddingValidation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process the training corpus\n",
    "\n",
    "# Set the class arguments\n",
    "digits_preprocess = 'removal'\n",
    "lemmatize_method = 'TextBlob'\n",
    "corpus_path = r'path/to/corpus/file'\n",
    "output_format = 'text'\n",
    "\n",
    "# Initialize the \"cleaner\" object\n",
    "cleaner = TextPreprocessing(digits=digits_preprocess, lemma=lemmatize_method, POS_noun=False, \n",
    "                            punctuation=True, lowercase=True, token=False)\n",
    "\n",
    "# Fit the corpus\n",
    "cleaner.FitText(corpus=corpus_path)\n",
    "\n",
    "# Store the cleaned corpus locally as text file\n",
    "cleaner.SaveText(file_format=output_format)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a language model with a custom hyperparameter configuration\n",
    "\n",
    "# Set the class arguments\n",
    "model_architecture = 'FastText'\n",
    "clean_corpus_path = r'path/to/cleaned/corpus/file'\n",
    "hyp_configuration = {'vector_size': 300,\n",
    "                    'window': 10,\n",
    "                    'min_count': 75,\n",
    "                    'epochs': 5}\n",
    "output_model_name = 'MyTrainedModel'\n",
    "\n",
    "# Initializer the \"trainer\" object\n",
    "trainer = NeuralEmbeddingModels(corpus=clean_corpus_path, model=model_architecture, hyperparameters=hyp_configuration)\n",
    "\n",
    "# Train the model\n",
    "trainer.Train()\n",
    "\n",
    "# S the trained model locally\n",
    "model_name = 'MyTrainedModel'\n",
    "trainer.SaveModel(filename=output_model_name)\n",
    "\n",
    "# Store the word vectors file locally\n",
    "trainer.WordVectors()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the trained model on a set of embedding validation task\n",
    "\n",
    "word_vectors_path = r'path/to/word/vectors/file'\n",
    "vector_dimension = hyp_configuration['vector_size']\n",
    "\n",
    "# Initialize the \"validator\" object\n",
    "validator = EmbeddingValidation(vector_file=word_vectors_path, vector_size=vector_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Relatedness task\n",
    "\n",
    "# Set the function argument\n",
    "relatedness_data_path = r'path/to/relatedness/file'\n",
    "metric = 'cosine'\n",
    "correlation = 'Spearman'\n",
    "\n",
    "validator.Relatedness(word_pairs=relatedness_data_path, eval_metric=metric, corr_metric='Spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Categorization task\n",
    "\n",
    "# Set the function argument\n",
    "categorization_data_path = r'path/to/categorization/file'\n",
    "category_number = 10\n",
    "seed = 420\n",
    "\n",
    "validator.Categorization(category_file=categorization_data_path, n_categories=category_number, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Analogy task\n",
    "\n",
    "# Set the function argument\n",
    "sample_dimension = 150\n",
    "seed = 420\n",
    "eval_metric = '3CosMUL' \n",
    "\n",
    "validator.Analogy(words=True, sample=sample_dimension, seed=seed, metric=eval_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Analysis task\n",
    "\n",
    "# Set the function argument\n",
    "sentiment_data_path = r'path/to/sentiment/analysis/file'\n",
    "sample_dimension = 25000\n",
    "seed = 420\n",
    "eval_metric = 'accuracy'\n",
    "\n",
    "validator.SentimentAnalysis(labeled_dataset=sentiment_data_path, sample=sample_dimension, \n",
    "                            seed=seed, metrics=eval_metric, preprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency Category task\n",
    "\n",
    "# Set the function argument\n",
    "sample_dimension = 15000\n",
    "freq_threshold_values = [250, 500, 750, 1000]\n",
    "eval_metric = 'accuracy'\n",
    "\n",
    "validator.FrequencyCategory(sample_size=sample_dimension, threshold_list=freq_threshold_values, metrics=eval_metric)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
